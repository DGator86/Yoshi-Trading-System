ai:
  provider: ollama
  # Pick a model you have pulled locally, e.g.:
  #   ollama pull llama3.1
  model: llama3.1
  endpoint: http://localhost:11434/api/chat
  timeout_seconds: 30
  system_prompt: >
    You are Moltbot, a trading assistant. Use the forecast data and
    risk constraints to propose a trade plan. Return JSON only.

risk:
  max_position_usd: 500
  max_leverage: 2
  daily_loss_limit_usd: 100

services:
  - name: slack
    type: webhook
    endpoint: https://hooks.slack.com/services/REPLACE/ME
    method: POST
    headers:
      Content-Type: application/json
